{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObservationalFairness_COMPAS",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Observational Fairness on COMPAS Dataset\n",
        "### Julia L. Wang\n",
        "\n",
        "Reproducing: \n",
        "\n",
        "*   Dressel, Julia, and Hany Farid (2018). “The accuracy, fairness, and limits of predicting recidivism.\"\n",
        "\n",
        "*   Wadsworth, Christina, Francesca Vera, and Chris Piech (2018). “Achieving fairness through adversarial learning: an application to recidivism prediction.”\n",
        "\n",
        "Using the COMPAS dataset. "
      ],
      "metadata": {
        "id": "7aSMxa7iATgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import chain\n",
        "\n",
        "# COMPAS dataset\n",
        "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "9pZO1qZ7F5fo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some Definitions\n",
        "\n",
        "**Calibration:** positive predictive value (PPV) parity and negative predictive value (NPV) parity since the risk scores are 0/1 for not recidivate/ recidivate\n",
        "\n",
        "\n",
        "*   PPV parity: P ( actually recidivate | model predicts recidivate) is equal for each demographic\n",
        "*   NPV parity: P( actually recidivate | model predicts won't recidivate) is equal for each demographic\n",
        "\n",
        "\n",
        "\n",
        "**False-positive parity:** P( model outputs recidivate | didn't actually recidivate) is equal regardless of demographic. "
      ],
      "metadata": {
        "id": "89IwklWtUCXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Part 1: Logistic Regression Model\n",
        "\n",
        "Reproducing Dressel et al. (2019) to predict 2-year recidivism. Dressel et al. split the data into 80% training and 20% testing, where they trained different models with 2  and 7 features respectively. This section will replicate their training using 2 features, and test for false-positive parity and calibration between Caucasian and African-American demographics. "
      ],
      "metadata": {
        "id": "gTPQm-q9A7Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting the data into training and test sets\n",
        "train, test = train_test_split(df, test_size=0.2) #20% test size\n",
        "\n",
        "## Training data we need- 2 features: age, priors_count\n",
        "train_data = torch.tensor(train[[\"age\", \"priors_count\"]].to_numpy().astype(np.float32))\n",
        "train_targets = torch.tensor(train[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "## Test data for testing all demographics\n",
        "test_data = torch.tensor(test[[\"age\", \"priors_count\"]].to_numpy().astype(np.float32))\n",
        "test_targets = torch.tensor(test[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "## Getting test data by race for comparison\n",
        "caucasian = df[(df.race == \"Caucasian\")]\n",
        "aa = df[(df.race == \"African-American\")]\n",
        "\n",
        "# get caucasian and african-american data in the training set\n",
        "aa_in_training = train.merge(aa, on=[\"id\"])\n",
        "caucasian_in_training = train.merge(caucasian, on=[\"id\"])\n",
        "\n",
        "# test sets: caucasian and aa not in the training set\n",
        "aa_test = aa[~aa.id.isin(aa_in_training.id)]\n",
        "caucasian_test = caucasian[~caucasian.id.isin(caucasian_in_training.id)]\n",
        "\n",
        "## final data and targets for each demographic\n",
        "cc_data = torch.tensor(caucasian_test[[\"age\", \"priors_count\"]].to_numpy().astype(np.float32))\n",
        "cc_targets = torch.tensor(caucasian_test[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "aa_data = torch.tensor(aa_test[[\"age\", \"priors_count\"]].to_numpy().astype(np.float32))\n",
        "aa_targets = torch.tensor(aa_test[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "# inputs into training logistic regression\n",
        "x_train = train_data\n",
        "y_train = train_targets"
      ],
      "metadata": {
        "id": "qxK1gU3PfD2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating logistic regression model\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "     def __init__(self, input_dim, output_dim):\n",
        "         super(LogisticRegression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "     def forward(self, x):\n",
        "         outputs = torch.sigmoid(self.linear(x))\n",
        "         return outputs\n",
        "\n",
        "model = LogisticRegression(2, 1)"
      ],
      "metadata": {
        "id": "Ik-OzBQGi888"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training the model\n",
        "\n",
        "# set model parameters\n",
        "criterion = torch.nn.BCELoss() # binary cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) #Adam optimizer\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(1000):\n",
        "    y_pred = model(x_train) # get model output by inputting the training data\n",
        "    loss = criterion(y_pred, y_train) # computing loss\n",
        "    loss.backward()                   # Backward pass\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1)%100 == 0: # print the accuracy and loss for every 100 epochs\n",
        "      model_out = torch.where(y_pred>0.50, 1, 0)\n",
        "      truth = torch.sum(torch.eq(model_out, y_train).int())\n",
        "      print(\"Model accuracy is \", truth/y_pred.shape[0], \". Loss is: \", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRb9H3fvnSEO",
        "outputId": "ca0f17e8-4b34-4b2e-e672-f70a6ede519e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is  tensor(0.6475) . Loss is:  0.6235053539276123\n",
            "Model accuracy is  tensor(0.6552) . Loss is:  0.6215925812721252\n",
            "Model accuracy is  tensor(0.6602) . Loss is:  0.6202848553657532\n",
            "Model accuracy is  tensor(0.6637) . Loss is:  0.6191103458404541\n",
            "Model accuracy is  tensor(0.6649) . Loss is:  0.6181541681289673\n",
            "Model accuracy is  tensor(0.6675) . Loss is:  0.6174333095550537\n",
            "Model accuracy is  tensor(0.6690) . Loss is:  0.6169244050979614\n",
            "Model accuracy is  tensor(0.6741) . Loss is:  0.6165862083435059\n",
            "Model accuracy is  tensor(0.6749) . Loss is:  0.6163738369941711\n",
            "Model accuracy is  tensor(0.6746) . Loss is:  0.6162476539611816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Running the model on the test sets\n",
        "\n",
        "caucasian_pred = model(cc_data) # caucasian test set\n",
        "aa_pred = model(aa_data)        # african-american test set\n",
        "overall_pred = model(test_data) # overall case with all demographics\n"
      ],
      "metadata": {
        "id": "zRId8AHwN7i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calibration and False-Positive parity"
      ],
      "metadata": {
        "id": "tzWOltkMBNpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FalsePosRate(model_out, y_test):\n",
        "  \"\"\"\n",
        "    model_out: models predictions of positive or negative (1/0)\n",
        "    y_test: the ground truth values\n",
        "    output: the false positive rate = # false positives / total true negatives\n",
        "  \"\"\"\n",
        "  false_pos_count = 0\n",
        "  total_neg_count = 0\n",
        "\n",
        "  for i in range(len(model_out)):\n",
        "    if y_test[i] == 0: # true  negative case\n",
        "      total_neg_count+=1\n",
        "      if model_out[i] != y_test[i]: #false pos when true negative & model predicts positive\n",
        "        false_pos_count+=1\n",
        "  # print(\"\\tAmount of false positives:\", false_pos_count)\n",
        "  # print(\"\\tAmount of negatives:\", total_neg_count)\n",
        "\n",
        "  return false_pos_count/total_neg_count\n",
        "\n",
        "# print(FalsePosRate(model_out, y_test))"
      ],
      "metadata": {
        "id": "OZHtCSCPrD6h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Calibration(model_out, targets):\n",
        "  \"\"\"\n",
        "    model_out: the models prediction of 0/1\n",
        "    targets: the ground truth values\n",
        "    outputs: PPV = P(ground truth = reoffend | model predicts reoffend)\n",
        "            NPV = 1 - P(ground truth = reoffend | model predicts won't reoffend)\n",
        "  \"\"\"\n",
        "  total_pos_count = 0\n",
        "  total_neg_count = 0\n",
        "  ppv_count = 0\n",
        "  npv_count = 0\n",
        "\n",
        "  for i in range(len(model_out)):\n",
        "    if model_out[i] == 0: # model negative (reoffend)\n",
        "      total_neg_count+=1\n",
        "      if targets[i] ==1:  # true positive\n",
        "        npv_count += 1\n",
        "        \n",
        "    else: # model positive case(reoffend)\n",
        "      total_pos_count += 1\n",
        "      if targets[i] == 1: # true positive\n",
        "        ppv_count += 1\n",
        "  \n",
        "  PPV = ppv_count/total_pos_count\n",
        "  NPV = 1-(npv_count/total_neg_count)\n",
        "\n",
        "  return PPV, NPV"
      ],
      "metadata": {
        "id": "xEJAxccsY9zd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Showing that the model fails to satisfy false-positive parity\n",
        "\n",
        "# Assigning model predictions to 0 or 1\n",
        "caucasian_pred_thresholded = torch.where(caucasian_pred > 0.5, 1, 0)\n",
        "aa_pred_thresholded = torch.where(aa_pred > 0.5, 1, 0)\n",
        "\n",
        "# Calculating false positive rate for each demographic\n",
        "caucasian_fpr = FalsePosRate(caucasian_pred_thresholded, cc_targets)\n",
        "print(\"Caucasian false positive rate:\", caucasian_fpr)\n",
        "\n",
        "aa_fpr = FalsePosRate(aa_pred_thresholded, aa_targets)\n",
        "print(\"African-American false positive rate:\", aa_fpr)\n",
        "\n",
        "## conclusion:\n",
        "print(\"Difference between them is:\", aa_fpr - caucasian_fpr)\n",
        "\n",
        "#since the false positive rates were not the same between the 2, \n",
        "#there is no false positive parity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvIXlpis7VqO",
        "outputId": "56f8d540-e938-4836-fe7e-80c480588134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caucasian false positive rate: 0.13486842105263158\n",
            "African-American false positive rate: 0.2657894736842105\n",
            "Difference between them is: 0.13092105263157894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Showing that the model satisfies calibration\n",
        "\n",
        "cc_ppv, cc_npv = Calibration(caucasian_pred_thresholded, cc_targets)\n",
        "aa_ppv, aa_npv = Calibration(aa_pred_thresholded, aa_targets)\n",
        "\n",
        "print(\"Caucasian PPV: \", cc_ppv, \" African-American PPV: \", aa_ppv, \"Difference = \", aa_ppv-cc_ppv)\n",
        "print(\"Caucasian NPV: \", cc_npv, \" African-American NPV: \", aa_npv, \"Difference = \", aa_npv-cc_npv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H66xGT_0x6Um",
        "outputId": "314ace1c-12c1-4908-9876-403ae1d4f01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caucasian PPV:  0.646551724137931  African-American PPV:  0.708092485549133 Difference =  0.061540761411201905\n",
            "Caucasian NPV:  0.6813471502590673  African-American NPV:  0.672289156626506 Difference =  -0.009057993632561323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing the differences in the demographics for false-positive parity and calibration\n",
        "\n",
        "For the purposes of this lab, I will define a difference to be significant if it 5% or greater. Thus, it can be seen above that the model does not satisfy false-positive parity since the difference between the false positive rates (FPRs) is 11.95%. On the other hand, the differences between the PPVs and NPVs are 4.12% and 3.44% respectively, which are both under 5% and therefore can be concluded to display parity. Since having both PPV parity and NPV parity means that we have calibration, the model satisfies calibration."
      ],
      "metadata": {
        "id": "P1no4tgxGgrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base rates"
      ],
      "metadata": {
        "id": "DUSrz3WpBU6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caucasian = df[(df.race == \"Caucasian\")]\n",
        "cc_recid = caucasian[\"two_year_recid\"].to_numpy().astype(np.float32)\n",
        "\n",
        "aa = df[(df.race == \"African-American\")]\n",
        "aa_recid = aa[\"two_year_recid\"].to_numpy().astype(np.float32)\n",
        "\n",
        "print(\"African-american recidivism base rate:\", np.sum(aa_recid)/aa.shape[0])\n",
        "print(\"Caucasian recidivism base rate:\", np.sum(cc_recid)/caucasian.shape[0])\n",
        "print(\"Difference between base rates: \", np.sum(aa_recid)/aa.shape[0]-np.sum(cc_recid)/caucasian.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mlcxOBuSKBl",
        "outputId": "209d3e61-ba3a-4c71-ec46-776464b91b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "African-american recidivism base rate: 0.5143398268398268\n",
            "Caucasian recidivism base rate: 0.39364303178484106\n",
            "Difference between base rates:  0.12069679505498576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The base rate for recidivism from the African-American demographic is higher than the Caucasian by 12.07%. False-positive parity occurs when people who did not reoffend are predicted to reoffend at the same rate. In this case, my model did not satisfy FFP with a 11.95% difference between false-positive rates, showing more false-positives for the African-American demographic. This is reflective of the base recidivism rate being higher since it causes the model to predict more recidivism for African-Americans."
      ],
      "metadata": {
        "id": "2qG5xoz7V35R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting thresholds"
      ],
      "metadata": {
        "id": "3beEh5zSR1AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Show adjusting thresholds satisfies false-positive parity \n",
        "thresholds = np.linspace(0, 1) # change threshold from 0 to 1 on the x-axis\n",
        "\n",
        "# generate FPR rates for cc and aa\n",
        "cc_fpr = []\n",
        "aa_fpr = []\n",
        "\n",
        "for i in thresholds:\n",
        "  # taking each model output with different thresholds\n",
        "  cc_thresholded = torch.where(caucasian_pred>i, 1, 0)\n",
        "  aa_thresholded = torch.where(aa_pred>i, 1, 0)\n",
        "  cc_fpr.append(FalsePosRate(cc_thresholded, cc_targets))\n",
        "  aa_fpr.append(FalsePosRate(aa_thresholded, aa_targets))\n",
        "\n",
        "# conversion to np array for plotting\n",
        "cc_fpr = np.array(cc_fpr)\n",
        "aa_fpr = np.array(aa_fpr)\n",
        "\n",
        "# plotting\n",
        "plt.plot(thresholds, aa_fpr, label = \"African-American\", color = \"m\")\n",
        "plt.plot(thresholds, cc_fpr, label = \"Caucasian\", color= \"c\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"False Positive Rate\")\n",
        "plt.title(\"Effect of threshold on FPR\")\n"
      ],
      "metadata": {
        "id": "nrvYndrKBlcg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "2d8a7683-4b13-4f24-b132-d59a6bcfd3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Effect of threshold on FPR')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting false positive rates with respect to different threshold values leads to the figure above. As such, it can be seen that a threshold of around 0.1 or 0.9 leads to false-positive parity where the rates match between demographics. Selecting these thresholds, let's try to check the calibration."
      ],
      "metadata": {
        "id": "vDZ7MZejBbfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Show that thresholds satisfying false-positive parity doesn't satisfy calibration\n",
        "caucasian_pred_thresholded = torch.where(caucasian_pred > 0.45, 1, 0)\n",
        "aa_pred_thresholded = torch.where(aa_pred > 0.7, 1, 0)\n",
        "\n",
        "cc_ppv, cc_npv = Calibration(caucasian_pred_thresholded, cc_targets)\n",
        "aa_ppv, aa_npv = Calibration(aa_pred_thresholded, aa_targets)\n",
        "\n",
        "print(\"For 0.1 Threshold:\")\n",
        "print(\"Caucasian PPV: \", cc_ppv, \" African-American PPV: \", aa_ppv, \"Difference = \", aa_ppv-cc_ppv)\n",
        "print(\"Caucasian NPV: \", cc_npv, \" African-American NPV: \", aa_npv, \"Difference = \", aa_npv-cc_npv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_oOShDkHRZx",
        "outputId": "14f208ac-168e-44ca-be2b-04fe604a057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 0.1 Threshold:\n",
            "Caucasian PPV:  0.5913978494623656  African-American PPV:  0.8415841584158416 Difference =  0.25018630895347593\n",
            "Caucasian NPV:  0.7215189873417722  African-American NPV:  0.5515151515151515 Difference =  -0.1700038358266207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the thresholds for which my model satisfied false-positive parity, the differences in PPV and NPV were significant (>5%), therefore, calibration is not satisfied after the threshold adjustment. "
      ],
      "metadata": {
        "id": "EFnUPWfxMjXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w1Qnqbkzy9BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further statistical testing is required to conclude the significance of the differences between demographics for false-positive rates, PPV, and NPV. "
      ],
      "metadata": {
        "id": "2uJni7BCPHCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Adversial Learning Procedure\n",
        "\n",
        "Reproducing Wadsworth et al. (2018) to produce more accurate classifier satisfying false-postiive partiy by introducing more features and using an adversial learning procedure."
      ],
      "metadata": {
        "id": "CI0eLi8fDvPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting data\n",
        "\n",
        "Wadsworth et al. (2018) had a training set size of 8230 and test size of 2213, which I will approximate as a 20% test size. "
      ],
      "metadata": {
        "id": "Qc5I_nfpn7te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# age, prior_count, sex, juv_misd_count, juv_other_count, juv_fel_count, c_charge_degree\n",
        "# encoding some features into binary\n",
        "encoded_sex = pd.Series(np.where(df.sex.values == 'Male', 1, 0), name=\"enc_sex\")\n",
        "encoded_charge_degree = pd.Series(np.where(df.c_charge_degree.values == 'F', 1, 0), name = \"enc_charge_degree\")\n",
        "encoded_race = pd.Series(np.where(df.race.values == \"Caucasian\", 1, 0), name=\"enc_race\")\n",
        "newdf = pd.concat([df, encoded_sex, encoded_charge_degree, encoded_race], axis=1)\n",
        "\n",
        "## Getting test data by race for comparison\n",
        "caucasian = newdf[(newdf.race == \"Caucasian\")]\n",
        "aa = newdf[(newdf.race == \"African-American\")]\n",
        "newdf = pd.concat([caucasian, aa]) # dataframe now only consists of caucasian and aa\n",
        "\n",
        "## Splitting the data into training and test sets\n",
        "train, test = train_test_split(newdf, test_size=0.2) #20% test size\n",
        "\n",
        "## Training data we need with 7 features\n",
        "train_data = torch.tensor(train[[\"age\", \"priors_count\", \"enc_sex\", \"enc_charge_degree\", \"juv_misd_count\", \"juv_other_count\", \"juv_fel_count\"]].to_numpy().astype(np.float32))\n",
        "train_targets = torch.tensor(train[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "train_targets2 = torch.tensor(train[[\"enc_race\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "## Test data for testing all demographics\n",
        "test_data = torch.tensor(test[[\"age\", \"priors_count\", \"enc_sex\", \"enc_charge_degree\", \"juv_misd_count\", \"juv_other_count\", \"juv_fel_count\"]].to_numpy().astype(np.float32))\n",
        "test_targets = torch.tensor(test[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "test_targets2 = torch.tensor(test[[\"enc_race\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "# get caucasian and african-american data in the training set\n",
        "aa_in_training = train.merge(aa, on=[\"id\"])\n",
        "caucasian_in_training = train.merge(caucasian, on=[\"id\"])\n",
        "\n",
        "# test sets: caucasian and aa not in the training set\n",
        "aa_test = aa[~aa.id.isin(aa_in_training.id)]\n",
        "caucasian_test = caucasian[~caucasian.id.isin(caucasian_in_training.id)]\n",
        "\n",
        "## final data and targets for each demographic\n",
        "cc_data = torch.tensor(caucasian_test[[\"age\", \"priors_count\", \"enc_sex\", \"enc_charge_degree\", \"juv_misd_count\", \"juv_other_count\", \"juv_fel_count\"]].to_numpy().astype(np.float32))\n",
        "cc_targets = torch.tensor(caucasian_test[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "cc_targets2 = torch.tensor(caucasian_test[[\"enc_race\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "aa_data = torch.tensor(aa_test[[\"age\", \"priors_count\", \"enc_sex\", \"enc_charge_degree\", \"juv_misd_count\", \"juv_other_count\", \"juv_fel_count\"]].to_numpy().astype(np.float32))\n",
        "aa_targets = torch.tensor(aa_test[[\"two_year_recid\"]].to_numpy().astype(np.float32))\n",
        "aa_targets2 = torch.tensor(aa_test[[\"enc_race\"]].to_numpy().astype(np.float32))\n",
        "\n",
        "# inputs into training logistic regression\n",
        "x_train = train_data\n",
        "y_train = train_targets   # recidivism\n",
        "y_train2 = train_targets2 # race\n",
        "newdf"
      ],
      "metadata": {
        "id": "W6o_ZO93j11z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "c00f4d47-6751-48b3-a377-9d79a875863f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88d24919-83e9-42dc-9a39-d7b6d1c57589\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>compas_screening_date</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>race</th>\n",
              "      <th>juv_fel_count</th>\n",
              "      <th>decile_score</th>\n",
              "      <th>juv_misd_count</th>\n",
              "      <th>juv_other_count</th>\n",
              "      <th>priors_count</th>\n",
              "      <th>days_b_screening_arrest</th>\n",
              "      <th>c_jail_in</th>\n",
              "      <th>c_jail_out</th>\n",
              "      <th>c_case_number</th>\n",
              "      <th>c_offense_date</th>\n",
              "      <th>c_arrest_date</th>\n",
              "      <th>c_days_from_compas</th>\n",
              "      <th>c_charge_degree</th>\n",
              "      <th>c_charge_desc</th>\n",
              "      <th>is_recid</th>\n",
              "      <th>r_case_number</th>\n",
              "      <th>r_charge_degree</th>\n",
              "      <th>r_days_from_arrest</th>\n",
              "      <th>r_offense_date</th>\n",
              "      <th>r_charge_desc</th>\n",
              "      <th>r_jail_in</th>\n",
              "      <th>r_jail_out</th>\n",
              "      <th>violent_recid</th>\n",
              "      <th>is_violent_recid</th>\n",
              "      <th>vr_case_number</th>\n",
              "      <th>vr_charge_degree</th>\n",
              "      <th>vr_offense_date</th>\n",
              "      <th>vr_charge_desc</th>\n",
              "      <th>type_of_assessment</th>\n",
              "      <th>decile_score.1</th>\n",
              "      <th>score_text</th>\n",
              "      <th>screening_date</th>\n",
              "      <th>v_type_of_assessment</th>\n",
              "      <th>v_decile_score</th>\n",
              "      <th>v_score_text</th>\n",
              "      <th>v_screening_date</th>\n",
              "      <th>in_custody</th>\n",
              "      <th>out_custody</th>\n",
              "      <th>priors_count.1</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>event</th>\n",
              "      <th>two_year_recid</th>\n",
              "      <th>enc_sex</th>\n",
              "      <th>enc_charge_degree</th>\n",
              "      <th>enc_race</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>edward riddle</td>\n",
              "      <td>edward</td>\n",
              "      <td>riddle</td>\n",
              "      <td>2014-02-19</td>\n",
              "      <td>Male</td>\n",
              "      <td>1974-07-23</td>\n",
              "      <td>41</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2014-02-18 05:08:24</td>\n",
              "      <td>2014-02-24 12:18:30</td>\n",
              "      <td>14002304CF10A</td>\n",
              "      <td>2014-02-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>F</td>\n",
              "      <td>Possession Burglary Tools</td>\n",
              "      <td>1</td>\n",
              "      <td>14004485CF10A</td>\n",
              "      <td>(F2)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014-03-31</td>\n",
              "      <td>Poss of Firearm by Convic Felo</td>\n",
              "      <td>2014-03-31</td>\n",
              "      <td>2014-04-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>6</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2014-02-19</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-02-19</td>\n",
              "      <td>2014-03-31</td>\n",
              "      <td>2014-04-18</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>elizabeth thieme</td>\n",
              "      <td>elizabeth</td>\n",
              "      <td>thieme</td>\n",
              "      <td>2014-03-16</td>\n",
              "      <td>Female</td>\n",
              "      <td>1976-06-03</td>\n",
              "      <td>39</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2014-03-15 05:35:34</td>\n",
              "      <td>2014-03-18 04:28:46</td>\n",
              "      <td>14004524MM10A</td>\n",
              "      <td>2014-03-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>M</td>\n",
              "      <td>Battery</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-03-16</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-03-16</td>\n",
              "      <td>2014-03-15</td>\n",
              "      <td>2014-03-18</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>747</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>bo bradac</td>\n",
              "      <td>bo</td>\n",
              "      <td>bradac</td>\n",
              "      <td>2013-11-04</td>\n",
              "      <td>Male</td>\n",
              "      <td>1994-06-10</td>\n",
              "      <td>21</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>428.0</td>\n",
              "      <td>2015-01-06 03:55:34</td>\n",
              "      <td>2015-01-07 03:38:44</td>\n",
              "      <td>13000017CF10A</td>\n",
              "      <td>2012-12-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>308.0</td>\n",
              "      <td>F</td>\n",
              "      <td>Insurance Fraud</td>\n",
              "      <td>1</td>\n",
              "      <td>15002891MM10A</td>\n",
              "      <td>(M1)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015-01-06</td>\n",
              "      <td>Battery</td>\n",
              "      <td>2015-01-06</td>\n",
              "      <td>2015-01-07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>15000258CF10A</td>\n",
              "      <td>(F2)</td>\n",
              "      <td>2015-01-06</td>\n",
              "      <td>Aggrav Battery w/Deadly Weapon</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-11-04</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>5</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-11-04</td>\n",
              "      <td>2015-01-06</td>\n",
              "      <td>2015-01-07</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>428</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>14</td>\n",
              "      <td>benjamin franc</td>\n",
              "      <td>benjamin</td>\n",
              "      <td>franc</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>Male</td>\n",
              "      <td>1988-06-01</td>\n",
              "      <td>27</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2013-11-25 06:31:06</td>\n",
              "      <td>2013-11-26 08:26:57</td>\n",
              "      <td>13016402CF10A</td>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>F</td>\n",
              "      <td>Poss 3,4 MDMA (Ecstasy)</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>4</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>4</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>857</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>16</td>\n",
              "      <td>kortney coleman</td>\n",
              "      <td>kortney</td>\n",
              "      <td>coleman</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>Female</td>\n",
              "      <td>1978-08-22</td>\n",
              "      <td>37</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-01-01 03:28:03</td>\n",
              "      <td>2013-01-02 01:12:19</td>\n",
              "      <td>13000053MM10A</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>M</td>\n",
              "      <td>Battery</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1186</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7207</th>\n",
              "      <td>10994</td>\n",
              "      <td>jarred payne</td>\n",
              "      <td>jarred</td>\n",
              "      <td>payne</td>\n",
              "      <td>2014-05-10</td>\n",
              "      <td>Male</td>\n",
              "      <td>1985-07-31</td>\n",
              "      <td>30</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2014-05-09 10:01:33</td>\n",
              "      <td>2014-05-10 08:28:12</td>\n",
              "      <td>14006477CF10A</td>\n",
              "      <td>2014-05-09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>M</td>\n",
              "      <td>Possess Cannabis/20 Grams Or Less</td>\n",
              "      <td>1</td>\n",
              "      <td>15013710CF10A</td>\n",
              "      <td>(F3)</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2015-10-21</td>\n",
              "      <td>Possession of Cannabis</td>\n",
              "      <td>2015-10-22</td>\n",
              "      <td>2015-10-22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-05-10</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-05-10</td>\n",
              "      <td>2015-10-22</td>\n",
              "      <td>2015-10-22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>529</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7208</th>\n",
              "      <td>10995</td>\n",
              "      <td>raheem smith</td>\n",
              "      <td>raheem</td>\n",
              "      <td>smith</td>\n",
              "      <td>2013-10-20</td>\n",
              "      <td>Male</td>\n",
              "      <td>1995-06-28</td>\n",
              "      <td>20</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2013-10-19 11:17:15</td>\n",
              "      <td>2013-10-20 08:13:06</td>\n",
              "      <td>13014650CF10A</td>\n",
              "      <td>2013-10-19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>F</td>\n",
              "      <td>Possession of Cocaine</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>9</td>\n",
              "      <td>High</td>\n",
              "      <td>2013-10-20</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>9</td>\n",
              "      <td>High</td>\n",
              "      <td>2013-10-20</td>\n",
              "      <td>2014-04-07</td>\n",
              "      <td>2014-04-27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7209</th>\n",
              "      <td>10996</td>\n",
              "      <td>steven butler</td>\n",
              "      <td>steven</td>\n",
              "      <td>butler</td>\n",
              "      <td>2013-11-23</td>\n",
              "      <td>Male</td>\n",
              "      <td>1992-07-17</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2013-11-22 05:18:27</td>\n",
              "      <td>2013-11-24 02:59:20</td>\n",
              "      <td>13016249CF10A</td>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>F</td>\n",
              "      <td>Deliver Cannabis</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>7</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-11-23</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>5</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2013-11-23</td>\n",
              "      <td>2013-11-22</td>\n",
              "      <td>2013-11-24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>860</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7210</th>\n",
              "      <td>10997</td>\n",
              "      <td>malcolm simmons</td>\n",
              "      <td>malcolm</td>\n",
              "      <td>simmons</td>\n",
              "      <td>2014-02-01</td>\n",
              "      <td>Male</td>\n",
              "      <td>1993-03-25</td>\n",
              "      <td>23</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2014-01-31 07:13:54</td>\n",
              "      <td>2014-02-02 04:03:52</td>\n",
              "      <td>14001422CF10A</td>\n",
              "      <td>2014-01-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>F</td>\n",
              "      <td>Leaving the Scene of Accident</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-02-01</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>5</td>\n",
              "      <td>Medium</td>\n",
              "      <td>2014-02-01</td>\n",
              "      <td>2014-01-31</td>\n",
              "      <td>2014-02-02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>790</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7212</th>\n",
              "      <td>11000</td>\n",
              "      <td>farrah jean</td>\n",
              "      <td>farrah</td>\n",
              "      <td>jean</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>Female</td>\n",
              "      <td>1982-11-17</td>\n",
              "      <td>33</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2014-03-08 08:06:02</td>\n",
              "      <td>2014-03-09 12:18:04</td>\n",
              "      <td>14003308CF10A</td>\n",
              "      <td>2014-03-08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>M</td>\n",
              "      <td>Battery on Law Enforc Officer</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Risk of Recidivism</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>Risk of Violence</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>2014-03-08</td>\n",
              "      <td>2014-03-09</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6150 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88d24919-83e9-42dc-9a39-d7b6d1c57589')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88d24919-83e9-42dc-9a39-d7b6d1c57589 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88d24919-83e9-42dc-9a39-d7b6d1c57589');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id              name      first  ... enc_sex enc_charge_degree enc_race\n",
              "6         8     edward riddle     edward  ...       1                 1        1\n",
              "8        10  elizabeth thieme  elizabeth  ...       0                 0        1\n",
              "9        13         bo bradac         bo  ...       1                 1        1\n",
              "10       14    benjamin franc   benjamin  ...       1                 1        1\n",
              "12       16   kortney coleman    kortney  ...       0                 0        1\n",
              "...     ...               ...        ...  ...     ...               ...      ...\n",
              "7207  10994      jarred payne     jarred  ...       1                 0        0\n",
              "7208  10995      raheem smith     raheem  ...       1                 1        0\n",
              "7209  10996     steven butler     steven  ...       1                 1        0\n",
              "7210  10997   malcolm simmons    malcolm  ...       1                 1        0\n",
              "7212  11000       farrah jean     farrah  ...       0                 0        0\n",
              "\n",
              "[6150 rows x 56 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature processing:** Features which were strings in the dataset were encoded into integer values- sex and crime degree were converted to binary 0 and 1s for the purposes of training the model. \n",
        "\n",
        "Wadsworth et al. (2018) used 10 features: charge degree, age, prior crimes, felonies, misdemeanors, days in jail, juvenile other, charges, juvenile misdemeanors, and jail history. To replicate this, I will be using features: age, sex, number of prior crimes, number of juvenile misdemeanors, number of juvinile felonies, and crime charge degree. "
      ],
      "metadata": {
        "id": "ZUzLbOrco9PU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating models\n",
        "\n",
        " 2 models: Wadsworth et al. implemented a predictor N and adversary A. I will be replicating the exact hyperparameters described in section 4 of Wadsworth et al. (2018). "
      ],
      "metadata": {
        "id": "sOyNIpVgmib4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Predictor N Model\n",
        "# 2 256-unit ReLU hidden layers\n",
        "class Predictor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Predictor, self).__init__()\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = torch.nn.Linear(7, 256)   # 7 features from the dataset\n",
        "        self.fc2 = torch.nn.Linear(256, 256) # 2x 256-unit ReLU \n",
        "        self.fc3 = torch.nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.fc1(x)) # 2x 256-unit ReLU\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x \n",
        "\n",
        "## Adversary A Model\n",
        "# 100 unit ReLU hidden layer\n",
        "class Adversary(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Adversary, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(1, 100) # logit and true recidivism value\n",
        "        self.fc2 = torch.nn.Linear(100, 1) # 100-unit ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x)) # sigmoid output\n",
        "        return x\n",
        "\n",
        "model1 = Predictor()\n",
        "model2 = Adversary()"
      ],
      "metadata": {
        "id": "GN95LGUvFr8c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameters\n",
        "# taken from section 4 of Wadsworth\n",
        "learning_rate = np.exp(-4)\n",
        "alpha = 1\n",
        "criterion = torch.nn.BCELoss(size_average=True) # binary cross entropy loss\n",
        "optimizer_pred = torch.optim.Adam(model1.parameters(), lr= learning_rate) #Adam optimizer\n",
        "optimizer_adv = torch.optim.Adam(model2.parameters(), lr = learning_rate)\n",
        "\n",
        "### Adverserial learning procedure\n",
        "# Following Figure 1 in Wadsworth\n",
        "\n",
        "for epoch in range(250):\n",
        "\n",
        "    ## zero out all gradients\n",
        "    optimizer_pred.zero_grad() #2 optimizers for the 2 models\n",
        "    optimizer_adv.zero_grad()\n",
        "\n",
        "    ## forward pass\n",
        "    pred_out = model1(x_train)   # input training data to model N\n",
        "    y_pred = model2(pred_out)    # predictor output -> Adversary\n",
        "\n",
        "    # computing adversary model loss, setting up for predictor\n",
        "    adv_loss = criterion(pred_out, y_train) # computing adversary loss wrt recidivism\n",
        "    pred_loss_p1 = criterion(y_pred, y_train2) # loss wrt race, to use in predictor loss\n",
        "\n",
        "    ## backward pass and update adversary model\n",
        "    adv_loss.backward(retain_graph=True) # retain graph: keeps all memory\n",
        "    optimizer_adv.step() # update adversary model parameters\n",
        "    optimizer_adv.zero_grad() # reset gradients to 0\n",
        "\n",
        "    ## forward pass\n",
        "    y_pred = model2(pred_out) # running adversary model again\n",
        "\n",
        "    ## computing predictor model loss\n",
        "    pred_loss_p1 = criterion(y_pred, y_train2) # loss wrt race, to use in predictor loss\n",
        "    pred_loss = adv_loss - alpha*pred_loss_p1\n",
        "\n",
        "    ## backward pass and updating predictor model parameters \n",
        "    pred_loss.backward()\n",
        "    optimizer_pred.step()\n",
        "\n",
        "    if (epoch+1)%10 == 0: # print the accuracy and loss for every 10 epochs\n",
        "      model_out = torch.where(pred_out>0.50, 1, 0)\n",
        "      truth = torch.sum(torch.eq(model_out, y_train).int())\n",
        "      print(\"Model accuracy is \", truth/pred_out.shape[0], \". Loss is: \", pred_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0vCmOMOifjo",
        "outputId": "2469ea27-21eb-4d25-e60b-b7632cbc784c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is  tensor(0.6488) . Loss is:  -0.07736295461654663\n",
            "Model accuracy is  tensor(0.6758) . Loss is:  -0.09219801425933838\n",
            "Model accuracy is  tensor(0.6742) . Loss is:  -0.09711688756942749\n",
            "Model accuracy is  tensor(0.6752) . Loss is:  -0.10008907318115234\n",
            "Model accuracy is  tensor(0.6768) . Loss is:  -0.10243254899978638\n",
            "Model accuracy is  tensor(0.6817) . Loss is:  -0.1043163537979126\n",
            "Model accuracy is  tensor(0.6817) . Loss is:  -0.10596656799316406\n",
            "Model accuracy is  tensor(0.6811) . Loss is:  -0.10747706890106201\n",
            "Model accuracy is  tensor(0.6815) . Loss is:  -0.10863715410232544\n",
            "Model accuracy is  tensor(0.6815) . Loss is:  -0.10966545343399048\n",
            "Model accuracy is  tensor(0.6827) . Loss is:  -0.11076027154922485\n",
            "Model accuracy is  tensor(0.6856) . Loss is:  -0.11143183708190918\n",
            "Model accuracy is  tensor(0.6864) . Loss is:  -0.11264210939407349\n",
            "Model accuracy is  tensor(0.6854) . Loss is:  -0.11345183849334717\n",
            "Model accuracy is  tensor(0.6872) . Loss is:  -0.11407351493835449\n",
            "Model accuracy is  tensor(0.6856) . Loss is:  -0.11531323194503784\n",
            "Model accuracy is  tensor(0.6896) . Loss is:  -0.11631041765213013\n",
            "Model accuracy is  tensor(0.6898) . Loss is:  -0.11732780933380127\n",
            "Model accuracy is  tensor(0.6911) . Loss is:  -0.11821794509887695\n",
            "Model accuracy is  tensor(0.6890) . Loss is:  -0.1183784008026123\n",
            "Model accuracy is  tensor(0.6902) . Loss is:  -0.11693954467773438\n",
            "Model accuracy is  tensor(0.6921) . Loss is:  -0.11852103471755981\n",
            "Model accuracy is  tensor(0.6921) . Loss is:  -0.1204829216003418\n",
            "Model accuracy is  tensor(0.6915) . Loss is:  -0.12047690153121948\n",
            "Model accuracy is  tensor(0.6858) . Loss is:  -0.11769211292266846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caucasian_pred = model2(model1(cc_data)) # caucasian test set\n",
        "aa_pred = model2(model1(aa_data))       # african-american test set\n",
        "overall_pred = model2(model1((test_data))) # overall case with all demographics"
      ],
      "metadata": {
        "id": "2iNNzIq1eIyF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Showing that the model fails to satisfy false-positive parity\n",
        "\n",
        "# Assigning model predictions to 0 or 1\n",
        "caucasian_pred_thresholded = torch.where(caucasian_pred > 0.5, 1, 0)\n",
        "aa_pred_thresholded = torch.where(aa_pred > 0.5, 1, 0)\n",
        "\n",
        "# Calculating false positive rate for each demographic\n",
        "caucasian_fpr = FalsePosRate(caucasian_pred_thresholded, cc_targets)\n",
        "print(\"Caucasian false positive rate:\", caucasian_fpr)\n",
        "\n",
        "aa_fpr = FalsePosRate(aa_pred_thresholded, aa_targets)\n",
        "print(\"African-American false positive rate:\", aa_fpr)\n",
        "\n",
        "## conclusion:\n",
        "print(\"Difference between them is:\", aa_fpr - caucasian_fpr)\n",
        "\n",
        "#since the false positive rates were not the same between the 2, \n",
        "#there is no false positive parity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-RDWEEEdy6B",
        "outputId": "104e05cc-570e-463f-a24c-3b9182dd3b9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caucasian false positive rate: 1.0\n",
            "African-American false positive rate: 1.0\n",
            "Difference between them is: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "Features used: sex, age, number of priors, \n",
        "\n",
        "Comparison to Wadsworth:\n",
        "\n",
        "False-positive disparity"
      ],
      "metadata": {
        "id": "nZ6RLkkWFtqc"
      }
    }
  ]
}